time_slot=5, num_his=1, num_pred=1, L=1, K=8, d=8, train_size=200, val_ratio=0.1, test_ratio=0.2, batch_size=50, max_epoch=100, patience=10, learning_rate=0.001, decay_epoch=10, traffic_file='../data/air/data.h5', SE_file='data/air/SE.txt', model_file='model/air.pt', log_file='logs/air_train', output_file='data/air/preds.npz'
loading data...
fullX: torch.Size([364, 1, 30])		 fullY: torch.Size([364, 2, 1])
trainX: torch.Size([200, 1, 30])		 trainY: torch.Size([200, 1, 30])
valX:   torch.Size([92, 1, 30])		valY:   torch.Size([92, 1, 30])
testX:   torch.Size([73, 1, 30])		testY:   torch.Size([73, 1, 30])
trainTE:   torch.Size([200, 2, 1])		valTE:   torch.Size([92, 2, 1])
testTE:   torch.Size([73, 2, 1])		fullTE:   torch.Size([364, 1, 30])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-05-16 19:58:12 | epoch: 0001/100, training time: 1.5s, inference time: 0.2s
train loss: 161.5396, val_loss: 402.8343
val loss decrease from inf to 402.8343, saving model to model/air.pt
2022-05-16 19:58:13 | epoch: 0002/100, training time: 1.1s, inference time: 0.2s
train loss: 155.3875, val_loss: 371.6636
val loss decrease from 402.8343 to 371.6636, saving model to model/air.pt
2022-05-16 19:58:14 | epoch: 0003/100, training time: 1.1s, inference time: 0.2s
train loss: 153.7509, val_loss: 363.1985
val loss decrease from 371.6636 to 363.1985, saving model to model/air.pt
2022-05-16 19:58:16 | epoch: 0004/100, training time: 1.1s, inference time: 0.2s
train loss: 153.1391, val_loss: 368.8309
2022-05-16 19:58:17 | epoch: 0005/100, training time: 1.2s, inference time: 0.2s
train loss: 152.5978, val_loss: 376.2677
2022-05-16 19:58:19 | epoch: 0006/100, training time: 1.7s, inference time: 0.3s
train loss: 152.2245, val_loss: 380.8061
2022-05-16 19:58:21 | epoch: 0007/100, training time: 1.3s, inference time: 0.2s
train loss: 151.6670, val_loss: 379.9480
2022-05-16 19:58:22 | epoch: 0008/100, training time: 1.1s, inference time: 0.2s
train loss: 151.3420, val_loss: 380.0457
2022-05-16 19:58:23 | epoch: 0009/100, training time: 1.1s, inference time: 0.2s
train loss: 151.1005, val_loss: 379.8033
2022-05-16 19:58:24 | epoch: 0010/100, training time: 1.1s, inference time: 0.2s
train loss: 150.6313, val_loss: 378.4548
2022-05-16 19:58:26 | epoch: 0011/100, training time: 1.1s, inference time: 0.2s
train loss: 150.4099, val_loss: 380.2770
2022-05-16 19:58:27 | epoch: 0012/100, training time: 1.1s, inference time: 0.3s
train loss: 149.9182, val_loss: 385.2292
2022-05-16 19:58:29 | epoch: 0013/100, training time: 1.9s, inference time: 0.3s
train loss: 149.6379, val_loss: 388.9383
2022-05-16 19:58:31 | epoch: 0014/100, training time: 1.6s, inference time: 0.3s
train loss: 149.3239, val_loss: 381.6557
2022-05-16 19:58:33 | epoch: 0015/100, training time: 1.6s, inference time: 0.3s
train loss: 149.0796, val_loss: 382.3509
2022-05-16 19:58:35 | epoch: 0016/100, training time: 1.5s, inference time: 0.3s
train loss: 148.6301, val_loss: 374.2640
2022-05-16 19:58:37 | epoch: 0017/100, training time: 1.5s, inference time: 0.2s
train loss: 148.5957, val_loss: 362.9569
val loss decrease from 363.1985 to 362.9569, saving model to model/air.pt
2022-05-16 19:58:39 | epoch: 0018/100, training time: 2.3s, inference time: 0.4s
train loss: 148.2159, val_loss: 384.3848
2022-05-16 19:58:41 | epoch: 0019/100, training time: 1.8s, inference time: 0.2s
train loss: 148.1849, val_loss: 373.3771
2022-05-16 19:58:43 | epoch: 0020/100, training time: 1.2s, inference time: 0.2s
train loss: 147.8188, val_loss: 376.9089
2022-05-16 19:58:44 | epoch: 0021/100, training time: 1.2s, inference time: 0.2s
train loss: 147.5931, val_loss: 375.8327
2022-05-16 19:58:45 | epoch: 0022/100, training time: 1.1s, inference time: 0.2s
train loss: 147.4648, val_loss: 375.4850
2022-05-16 19:58:47 | epoch: 0023/100, training time: 1.1s, inference time: 0.2s
train loss: 147.0913, val_loss: 374.6225
2022-05-16 19:58:48 | epoch: 0024/100, training time: 1.2s, inference time: 0.2s
train loss: 146.8751, val_loss: 365.3890
2022-05-16 19:58:49 | epoch: 0025/100, training time: 1.1s, inference time: 0.2s
train loss: 146.6665, val_loss: 370.6062
2022-05-16 19:58:51 | epoch: 0026/100, training time: 1.1s, inference time: 0.2s
train loss: 146.5863, val_loss: 375.3764
2022-05-16 19:58:52 | epoch: 0027/100, training time: 1.2s, inference time: 0.2s
train loss: 146.2844, val_loss: 369.5557
2022-05-16 19:58:53 | epoch: 0028/100, training time: 1.1s, inference time: 0.2s
train loss: 146.2906, val_loss: 364.7737
2022-05-16 19:58:55 | epoch: 0029/100, training time: 1.1s, inference time: 0.2s
train loss: 145.9305, val_loss: 384.3626
2022-05-16 19:58:56 | epoch: 0030/100, training time: 1.1s, inference time: 0.2s
train loss: 146.0441, val_loss: 381.5256
2022-05-16 19:58:57 | epoch: 0031/100, training time: 1.1s, inference time: 0.2s
train loss: 145.6436, val_loss: 368.9046
2022-05-16 19:58:59 | epoch: 0032/100, training time: 1.1s, inference time: 0.2s
train loss: 145.6215, val_loss: 369.7274
2022-05-16 19:59:00 | epoch: 0033/100, training time: 1.1s, inference time: 0.2s
train loss: 145.2926, val_loss: 370.3560
2022-05-16 19:59:01 | epoch: 0034/100, training time: 1.1s, inference time: 0.2s
train loss: 145.1067, val_loss: 369.9921
2022-05-16 19:59:02 | epoch: 0035/100, training time: 1.1s, inference time: 0.2s
train loss: 145.0621, val_loss: 370.4583
2022-05-16 19:59:04 | epoch: 0036/100, training time: 1.1s, inference time: 0.2s
train loss: 144.9912, val_loss: 377.9928
2022-05-16 19:59:05 | epoch: 0037/100, training time: 1.1s, inference time: 0.2s
train loss: 144.7509, val_loss: 369.9258
2022-05-16 19:59:06 | epoch: 0038/100, training time: 1.1s, inference time: 0.2s
train loss: 144.6228, val_loss: 363.6260
2022-05-16 19:59:08 | epoch: 0039/100, training time: 1.2s, inference time: 0.2s
train loss: 144.5107, val_loss: 370.4861
2022-05-16 19:59:09 | epoch: 0040/100, training time: 1.1s, inference time: 0.2s
train loss: 144.3870, val_loss: 374.1841
2022-05-16 19:59:10 | epoch: 0041/100, training time: 1.1s, inference time: 0.2s
train loss: 144.3650, val_loss: 370.7841
2022-05-16 19:59:12 | epoch: 0042/100, training time: 1.1s, inference time: 0.2s
train loss: 144.1107, val_loss: 371.2937
2022-05-16 19:59:13 | epoch: 0043/100, training time: 1.1s, inference time: 0.2s
train loss: 143.9858, val_loss: 369.8656
2022-05-16 19:59:14 | epoch: 0044/100, training time: 1.1s, inference time: 0.2s
train loss: 144.0662, val_loss: 371.5959
2022-05-16 19:59:16 | epoch: 0045/100, training time: 1.1s, inference time: 0.2s
train loss: 143.7497, val_loss: 375.6441
2022-05-16 19:59:17 | epoch: 0046/100, training time: 1.1s, inference time: 0.2s
train loss: 143.8882, val_loss: 376.2888
2022-05-16 19:59:18 | epoch: 0047/100, training time: 1.1s, inference time: 0.2s
train loss: 143.6231, val_loss: 372.7021
2022-05-16 19:59:20 | epoch: 0048/100, training time: 1.1s, inference time: 0.2s
train loss: 143.5078, val_loss: 371.4983
2022-05-16 19:59:21 | epoch: 0049/100, training time: 1.1s, inference time: 0.2s
train loss: 143.3664, val_loss: 371.2747
2022-05-16 19:59:22 | epoch: 0050/100, training time: 1.2s, inference time: 0.2s
train loss: 143.5093, val_loss: 371.0736
2022-05-16 19:59:24 | epoch: 0051/100, training time: 1.1s, inference time: 0.2s
train loss: 143.3625, val_loss: 373.2415
2022-05-16 19:59:25 | epoch: 0052/100, training time: 1.1s, inference time: 0.2s
train loss: 143.1813, val_loss: 368.6389
2022-05-16 19:59:26 | epoch: 0053/100, training time: 1.1s, inference time: 0.2s
train loss: 143.0634, val_loss: 371.1529
2022-05-16 19:59:27 | epoch: 0054/100, training time: 1.1s, inference time: 0.2s
train loss: 142.9731, val_loss: 371.3042
2022-05-16 19:59:29 | epoch: 0055/100, training time: 1.2s, inference time: 0.2s
train loss: 142.9288, val_loss: 369.0764
2022-05-16 19:59:30 | epoch: 0056/100, training time: 1.1s, inference time: 0.2s
train loss: 142.7706, val_loss: 380.4453
2022-05-16 19:59:31 | epoch: 0057/100, training time: 1.1s, inference time: 0.2s
train loss: 142.6678, val_loss: 371.7598
2022-05-16 19:59:33 | epoch: 0058/100, training time: 1.2s, inference time: 0.2s
train loss: 142.8619, val_loss: 364.8056
2022-05-16 19:59:34 | epoch: 0059/100, training time: 1.1s, inference time: 0.2s
train loss: 142.6729, val_loss: 363.4250
2022-05-16 19:59:35 | epoch: 0060/100, training time: 1.1s, inference time: 0.2s
train loss: 142.5075, val_loss: 368.7975
2022-05-16 19:59:37 | epoch: 0061/100, training time: 1.2s, inference time: 0.2s
train loss: 142.6697, val_loss: 373.3404
2022-05-16 19:59:38 | epoch: 0062/100, training time: 1.1s, inference time: 0.2s
train loss: 142.2541, val_loss: 368.4944
2022-05-16 19:59:39 | epoch: 0063/100, training time: 1.1s, inference time: 0.2s
train loss: 142.2225, val_loss: 374.8485
2022-05-16 19:59:41 | epoch: 0064/100, training time: 1.1s, inference time: 0.2s
train loss: 142.0974, val_loss: 377.5289
2022-05-16 19:59:42 | epoch: 0065/100, training time: 1.1s, inference time: 0.2s
train loss: 141.9964, val_loss: 374.4013
2022-05-16 19:59:44 | epoch: 0066/100, training time: 1.6s, inference time: 0.2s
train loss: 142.3206, val_loss: 363.9174
2022-05-16 19:59:45 | epoch: 0067/100, training time: 1.2s, inference time: 0.2s
train loss: 141.8759, val_loss: 371.2874
2022-05-16 19:59:46 | epoch: 0068/100, training time: 1.1s, inference time: 0.2s
train loss: 141.8959, val_loss: 374.2797
2022-05-16 19:59:48 | epoch: 0069/100, training time: 1.1s, inference time: 0.2s
train loss: 141.7219, val_loss: 370.5756
2022-05-16 19:59:49 | epoch: 0070/100, training time: 1.1s, inference time: 0.2s
train loss: 141.7305, val_loss: 369.9541
2022-05-16 19:59:50 | epoch: 0071/100, training time: 1.2s, inference time: 0.2s
train loss: 141.6271, val_loss: 375.0845
2022-05-16 19:59:52 | epoch: 0072/100, training time: 1.2s, inference time: 0.2s
train loss: 141.6263, val_loss: 372.3058
2022-05-16 19:59:53 | epoch: 0073/100, training time: 1.2s, inference time: 0.2s
train loss: 141.4928, val_loss: 370.1471
2022-05-16 19:59:55 | epoch: 0074/100, training time: 1.1s, inference time: 0.2s
train loss: 141.2238, val_loss: 369.7979
2022-05-16 19:59:56 | epoch: 0075/100, training time: 1.1s, inference time: 0.2s
train loss: 141.2182, val_loss: 369.8829
2022-05-16 19:59:57 | epoch: 0076/100, training time: 1.1s, inference time: 0.2s
train loss: 141.2129, val_loss: 368.5724
2022-05-16 19:59:58 | epoch: 0077/100, training time: 1.1s, inference time: 0.2s
train loss: 141.1809, val_loss: 369.4471
2022-05-16 20:00:00 | epoch: 0078/100, training time: 1.1s, inference time: 0.2s
train loss: 141.0156, val_loss: 371.7057
2022-05-16 20:00:01 | epoch: 0079/100, training time: 1.1s, inference time: 0.2s
train loss: 140.9518, val_loss: 368.1797
2022-05-16 20:00:02 | epoch: 0080/100, training time: 1.1s, inference time: 0.2s
train loss: 141.1328, val_loss: 373.2684
2022-05-16 20:00:04 | epoch: 0081/100, training time: 1.1s, inference time: 0.2s
train loss: 140.7988, val_loss: 373.2627
2022-05-16 20:00:05 | epoch: 0082/100, training time: 1.2s, inference time: 0.2s
train loss: 140.7377, val_loss: 370.3309
2022-05-16 20:00:06 | epoch: 0083/100, training time: 1.1s, inference time: 0.2s
train loss: 140.7008, val_loss: 369.9873
2022-05-16 20:00:08 | epoch: 0084/100, training time: 1.2s, inference time: 0.2s
train loss: 140.5729, val_loss: 367.6335
2022-05-16 20:00:09 | epoch: 0085/100, training time: 1.2s, inference time: 0.2s
train loss: 140.5518, val_loss: 369.2356
2022-05-16 20:00:11 | epoch: 0086/100, training time: 1.2s, inference time: 0.2s
train loss: 140.4640, val_loss: 372.0702
2022-05-16 20:00:12 | epoch: 0087/100, training time: 1.1s, inference time: 0.2s
train loss: 140.5953, val_loss: 370.1608
2022-05-16 20:00:13 | epoch: 0088/100, training time: 1.1s, inference time: 0.2s
train loss: 140.6478, val_loss: 368.1450
2022-05-16 20:00:15 | epoch: 0089/100, training time: 1.1s, inference time: 0.2s
train loss: 140.4358, val_loss: 368.9369
2022-05-16 20:00:16 | epoch: 0090/100, training time: 1.1s, inference time: 0.2s
train loss: 140.3817, val_loss: 370.6660
2022-05-16 20:00:17 | epoch: 0091/100, training time: 1.1s, inference time: 0.2s
train loss: 140.2146, val_loss: 369.0796
2022-05-16 20:00:18 | epoch: 0092/100, training time: 1.1s, inference time: 0.2s
train loss: 140.4122, val_loss: 366.0349
2022-05-16 20:00:20 | epoch: 0093/100, training time: 1.1s, inference time: 0.2s
train loss: 140.2622, val_loss: 369.1961
2022-05-16 20:00:21 | epoch: 0094/100, training time: 1.1s, inference time: 0.2s
train loss: 140.1291, val_loss: 372.1227
2022-05-16 20:00:22 | epoch: 0095/100, training time: 1.1s, inference time: 0.2s
train loss: 140.0127, val_loss: 372.0602
2022-05-16 20:00:24 | epoch: 0096/100, training time: 1.1s, inference time: 0.2s
train loss: 140.0990, val_loss: 364.6722
2022-05-16 20:00:25 | epoch: 0097/100, training time: 1.2s, inference time: 0.2s
train loss: 139.9852, val_loss: 365.9135
2022-05-16 20:00:26 | epoch: 0098/100, training time: 1.1s, inference time: 0.2s
train loss: 139.8431, val_loss: 376.1853
2022-05-16 20:00:28 | epoch: 0099/100, training time: 1.1s, inference time: 0.2s
train loss: 140.0026, val_loss: 375.5125
2022-05-16 20:00:29 | epoch: 0100/100, training time: 1.1s, inference time: 0.2s
train loss: 139.6584, val_loss: 366.2289
Training is completed, and model has been stored as model/air.pt
**** testing model ****
loading model from model/air.pt
model restored!
evaluating...
test             10.80		15.57		nan%
performance in each prediction step
step: 01         10.80		15.57		nan%
average:         10.80		15.57		nan%
